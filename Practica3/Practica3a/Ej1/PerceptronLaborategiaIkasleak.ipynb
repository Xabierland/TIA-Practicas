{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codifica tus própios perceptrones para implementar puertas lógicas\n",
    "En las partes que aparecen así\n",
    "```python\n",
    "pass  # ⬅️✏️\n",
    "```\n",
    "necesitas rellenar código antes de pasar a la siguiente celda.\n",
    "\n",
    "Revisa las transparencias de clase para llevar a cabo estos ejercicios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comenzaremos por implementar una **neurona AND**. Ojo!! No la vamos a entrenar, vamos a asumir que conocemos los pesos (los hemos calculado en clase) \n",
    "\n",
    "Para ello:\n",
    "\n",
    "1) suponemos que el entrenamiento ya está previamente hecho y por lo tanto conocemos los pesos apropiados (consultar las transparencias)\n",
    "\n",
    "2) Nos piden implementar la neurona AND y probar con un item o ejemplo, por ejemplo un vector de input 0,1 que la salida es correcta\n",
    "\n",
    "Recordad que en clase hemos descubierto que los pesos apropiados son:\n",
    "0.66 y 0.8, así que el vector de pesos será [0.66,0.8] y el bias será 1 y el peso para el bias será -0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Definir dos vectores (listas): input my_x, pesos my_w\n",
    "my_x = [0, 1]#input un item\n",
    "my_w = [0.66, 0.80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicar dos vectores elemento a elemento\n",
    "def mul(a, b):\n",
    "    \"\"\"\n",
    "    Devolver una lista c, de la misma longitud que a y b, donde \n",
    "    cada elemento c[i] = a[i] * b[i]\n",
    "    \"\"\"\n",
    "    return [a[i] * b[i] for i in range(len(a))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.8]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test la función mul() con un item my_x \n",
    "# y los pesos descubiertos en clase my_w, el resultado debería ser \n",
    "# el vector [0.0,0.8]\n",
    "mul(my_x, my_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define el bias my_bias y el peso descubierto en clase asociado a ese bias\n",
    "# añadiré el bias a el vector de pesos my_w generando un nuevo vector my_wPlusWBias.\n",
    "# Posibles errores: Recordad que en Python las variables con punteros\n",
    "# y el insertar si lo ejecutáis varias veces los valores \n",
    "# se van acumulando dependiendo de cómo hagáis la inserción\n",
    "# my_wPlusWBias debería contener [-0.97, 0.66, 0.8]. Pista para hacer copias de un vector. copiaV=v[:] o copiaV=v.copy()\n",
    "\n",
    "my_bias  = 1\n",
    "my_wbias = -0.97\n",
    "\n",
    "my_wPlusWBias = [my_wbias] + my_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neurona lineal\n",
    "def distanciaDelCoseno(x, weights, bias):\n",
    "    \"\"\"\n",
    "    El producto escalar (producto punto) de dos vectores y la similitud de coseno no son completamente equivalentes \n",
    "    ya que la similitud del coseno solo se preocupa por la diferencia de ángulo, \n",
    "    mientras que el producto de punto se preocupa por el ángulo y la magnitud\n",
    "    Pero en muchas ocasiones se emplean indistintamente\n",
    "    Así pues, esta función devuelve el valor escalar de la neurona, es decir, \n",
    "    el producto escalar entre el vector de entrada añadiendo el bias y el vector de los pesos\n",
    "    recordad que \"sum(list)\" computa la suma de los elementos de una lista\n",
    "    Así pues se comenzará por añadir el bías en la posición 0 del vector de entrada \n",
    "    antes de llevar a cabo el producto escalar para así tener dos vectores de \n",
    "    la misma longitud. Emplea la función mul que ya has programado\n",
    "    \"\"\"\n",
    "    x = [bias] + x\n",
    "    return sum(mul(x, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.16999999999999993"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test distanciaDelCoseno que debería darte -0.16999999999999993 para los datos my_x, my_wPlusWBias, my_bias\n",
    "distanciaDelCoseno(my_x, my_wPlusWBias, my_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una neurona perceptron completa, distancia del coseno y activación\n",
    "def neuron(x, weights, bias):\n",
    "    \"\"\"\n",
    "    Devolverá el output de una neurona clásica \n",
    "    (reutilizar la distancia del coseno definida previamente) \n",
    "    y añadir la función de activación (step function): si >=0 entonces 1 sino -1\n",
    "    \"\"\"\n",
    "    return 1 if distanciaDelCoseno(x, weights, bias)>=0 else -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testar la función neuron() para el item my_x y el bias my_b \n",
    "# y el vector de pesos my_wPlusWBias\n",
    "# debería de dar -1 para el input item [0,1] con el bias 1 \n",
    "# y el vector de pesos hayado en clase\n",
    "neuron(my_x, my_wPlusWBias, my_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Package AND neuron weights and bias\n",
    "def and_neuron(x):\n",
    "    \"\"\"\n",
    "    Devuelve x1 AND x2 suponiendo que la hemos entrenado\n",
    "    y que en ese entrenamiento hemos aprendido los pesos apropiados \n",
    "    (mirar las transparencias de clase). Así pues inicializaremos \n",
    "    una la variable local and_w con los pesos aprendidos \n",
    "    y a 1 la variable local and_bias \n",
    "    y ejecutaremos la función neurona para el item x\"\"\"\n",
    "    and_w    = [-0.97,0.66, 0.80]#initialization of the weights and_w\n",
    "    and_bias = 1#initialization of the bias and_bias\n",
    "    return neuron(x, and_w, and_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nos piden probar la puerta para toda la colección de inputs posibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen los items de entrada para testar\n",
    "# las neuronas AND y las posteriores que implementaremos (OR, XOR)\n",
    "# CUIDADO para la neurona NOT hará falta otra colección dado \n",
    "# que los vectores de entrada a la NOT no tienen dos dimensiones sino 1\n",
    "my_x_collection = [\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando el output de la neurona AND\n",
      "[0, 0] -1.000\n",
      "[0, 1] -1.000\n",
      "[1, 0] -1.000\n",
      "[1, 1] 1.000\n"
     ]
    }
   ],
   "source": [
    "# Para los items de entrada my_x_collection la salida debería ser \n",
    "# -1, -1, -1, 1\n",
    "print('Testando el output de la neurona AND')\n",
    "#bucle para ir obteniendo el output de la neurona AND para cada item del input\n",
    "for my_x in my_x_collection:\n",
    "    print(my_x, f'{and_neuron(my_x):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurona OR\n",
    "\n",
    "Hasta ahora solo habéis tenido que implementar la neurona AND sin tener que entrenarla dado que ya conocíamos los pesos que habíamos aprendido en clase. Es decir, no habéis implementado en Python la fase de entrenamiento de la neurona para determinar los pesos. Ahora se os pide que entrenéis una neurona OR, de forma que realicéis iteraciones sobre los items del input. Para ello los pasos serán:\n",
    "1) Inicializar un vector de pesos de forma random (emplear la librería random **from random import random**)\n",
    "\n",
    "2) Por cada item del input aplicar la neurona y si la predicción realizada por la neurona en base a aplicar  la distancia del coseno y la función de activación no es correcta, entonces ajustar los pesos consecuentemente\n",
    "\n",
    "3) Repetir el paso 2 hasta convergencia (es decir, hasta que todos los items estén correctamente clasificados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando una neurona OR hasta convergencia\n",
      "Vuelta 1: Pesos actualizados OR: [0.13436424411240122, 0.8474337369372327, 1.7637746189766141]\n",
      "Vuelta 2: Pesos actualizados OR: [0.13436424411240122, 1.8474337369372327, 1.7637746189766141]\n",
      "Vuelta 3: Pesos actualizados OR: [-0.8656357558875988, 1.8474337369372327, 1.7637746189766141]\n",
      "Vuelta 4: Pesos actualizados OR: [-0.8656357558875988, 1.8474337369372327, 1.7637746189766141]\n"
     ]
    }
   ],
   "source": [
    "from random import seed, random\n",
    "\n",
    "# Inicialización\n",
    "print('Entrenando una neurona OR hasta convergencia')\n",
    "notConverge=True\n",
    "seed(1)\n",
    "\n",
    "orWeights= [random() for i in range(3)]\n",
    "orBias = 1\n",
    "orGoldOutputs = [-1,1,1,1]\n",
    "\n",
    "# Entrenamiento\n",
    "numeroVuelta = 0\n",
    "while notConverge:\n",
    "    notConverge = False\n",
    "    for i, my_x in enumerate(my_x_collection):\n",
    "        x_with_bias = [orBias] + my_x  # Agrega el bias al vector de entrada\n",
    "        predicted_output = neuron(my_x, orWeights, orBias)\n",
    "        \n",
    "        # Si la predicción no coincide con la salida esperada, ajustar pesos\n",
    "        if predicted_output != orGoldOutputs[i]:\n",
    "            adjustment = 1 if orGoldOutputs[i] == 1 else -1\n",
    "            orWeights = [orWeights[j] + adjustment * x_with_bias[j] for j in range(len(orWeights))]\n",
    "            notConverge = True  # Continuar iterando hasta que todo esté correcto\n",
    "    numeroVuelta += 1\n",
    "    print(f\"Vuelta {numeroVuelta}: Pesos actualizados OR:\", orWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurona NOT\n",
    "\n",
    "Ahora implementa el entrenamiento de una neurona NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen los items de entrada para testar\n",
    "# la neurona NOT. \n",
    "# Recordad que los vectores de entrada a la NOT no tienen dos dimensiones sino 1\n",
    "my_x_collection = [\n",
    "    [0],\n",
    "    [1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando una neurona NOT hasta convergencia\n",
      "Vuelta 1: Pesos actualizados NOT: [-0.8656357558875988, 1.8474337369372327, 1.7637746189766141]\n"
     ]
    }
   ],
   "source": [
    "from random import seed, random\n",
    "\n",
    "\n",
    "# Inicializaciones\n",
    "print('Entrenando una neurona NOT hasta convergencia')\n",
    "notConverge = True\n",
    "seed(1)\n",
    "\n",
    "notWeights = [random(), random()]\n",
    "notBias   = 1\n",
    "notGoldOutput = [1, -1]\n",
    "\n",
    "#entrenando\n",
    "numeroVuelta = 0\n",
    "while notConverge:\n",
    "    notConverge = False\n",
    "    for i, my_x in enumerate(my_x_collection):\n",
    "        x_with_bias = [orBias] + my_x  # Agrega el bias al vector de entrada\n",
    "        predicted_output = neuron(my_x, orWeights, orBias)\n",
    "        \n",
    "        # Si la predicción no coincide con la salida esperada, ajustar pesos\n",
    "        if predicted_output != orGoldOutputs[i]:\n",
    "            adjustment = 1 if orGoldOutputs[i] == 1 else -1\n",
    "            orWeights = [orWeights[j] + adjustment * x_with_bias[j] for j in range(len(orWeights))]\n",
    "            notConverge = True  # Continuar iterando hasta que todo esté correcto\n",
    "    numeroVuelta += 1\n",
    "    print(f\"Vuelta {numeroVuelta}: Pesos actualizados NOT:\", orWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted average\n",
    "\n",
    "Ahora implementa el weighted average explicado en las transparencias de clase ¿qué puedes decir acerca de las actualizaciones de los pesos y el número de epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen los items de entrada para testar\n",
    "# las neuronas AND y las posteriores que implementaremos (OR, XOR)\n",
    "# CUIDADO para la neurona NOT hará falta otra colección dado \n",
    "# que los vectores de entrada a la NOT no tienen dos dimensiones sino 1\n",
    "my_x_collection = [\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrixAverage(m):\n",
    "    res=list()\n",
    "    acum=list()\n",
    "    if len(m) > 0:\n",
    "        res=[0]*len(m[0])\n",
    "        for v in m:\n",
    "            res = [a+b for a,b in zip (res,v)]\n",
    "        acum=[elem/len(m) for elem in res]\n",
    "    return acum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "matrix=[[2,3,4],[2,3,4],[2,3,4]]\n",
    "print(matrixAverage(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando una neurona OR hasta convergencia\n",
      "Vuelta 1: Pesos actualizados OR: [0.13436424411240122, 0.8474337369372327, 1.7637746189766141]\n",
      "Vuelta 2: Pesos actualizados OR: [0.13436424411240122, 1.8474337369372327, 1.7637746189766141]\n",
      "Vuelta 3: Pesos actualizados OR: [-0.8656357558875988, 1.8474337369372327, 1.7637746189766141]\n",
      "Vuelta 4: Pesos actualizados OR: [-0.8656357558875988, 1.8474337369372327, 1.7637746189766141]\n",
      "\n",
      "Promedio ponderado de los pesos OR: [-0.3656357558875988, 1.5974337369372327, 1.7637746189766141]\n"
     ]
    }
   ],
   "source": [
    "from random import seed, random\n",
    "\n",
    "# Inicializaciones\n",
    "print('Entrenando una neurona OR hasta convergencia')\n",
    "notConverge=True\n",
    "seed(1)\n",
    "\n",
    "orWeights= [random() for i in range(3)]\n",
    "orBias = 1\n",
    "orGoldOutputs = [-1,1,1,1]\n",
    "\n",
    "# Historial de pesos\n",
    "weightHistory = []\n",
    "\n",
    "# Entrenamiento\n",
    "numeroVuelta = 0\n",
    "while notConverge:\n",
    "    notConverge = False\n",
    "    epoch_weights = orWeights.copy()  # Copia de los pesos para acumular en cada epoch\n",
    "    for i, my_x in enumerate(my_x_collection):\n",
    "        x_with_bias = [orBias] + my_x  # Agrega el bias al vector de entrada\n",
    "        \n",
    "        # Verificar si la predicción coincide con la salida esperada\n",
    "        if neuron(my_x, orWeights, orBias) != orGoldOutputs[i]:\n",
    "            # Ajuste de pesos basado en el error\n",
    "            adjustment = 1 if orGoldOutputs[i] == 1 else -1\n",
    "            orWeights = [orWeights[j] + adjustment * x_with_bias[j] for j in range(len(orWeights))]\n",
    "            notConverge = True  # Continuar iterando hasta convergencia\n",
    "    weightHistory.append(orWeights.copy())  # Guardar los pesos de esta epoch\n",
    "    numeroVuelta += 1\n",
    "    print(f\"Vuelta {numeroVuelta}: Pesos actualizados OR:\", orWeights)\n",
    "\n",
    "# Calcular el promedio ponderado de los pesos al finalizar el entrenamiento\n",
    "averageWeights = matrixAverage(weightHistory)\n",
    "print(\"\\nPromedio ponderado de los pesos OR:\", averageWeights)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package OR neuron weights and bias\n",
    "def or_neuron(x):\n",
    "    \"\"\"\n",
    "    Devuelve x1 AND x2 suponiendo que la hemos entrenado\n",
    "    y que en ese entrenamiento hemos aprendido los pesos apropiados \n",
    "    (mirar las transparencias de clase). Así pues inicializaremos \n",
    "    una la variable local and_w con los pesos aprendidos \n",
    "    y a 1 la variable local and_bias \n",
    "    y ejecutaremos la función neurona para el item x\"\"\"\n",
    "    or_w    = [-0.3656,0.8474, 0.7637]#initialization of the weights and_w\n",
    "    or_bias = 1#initialization of the bias and_bias\n",
    "    return neuron(x, or_w, or_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando el output de la neurona OR\n",
      "Input: [0, 0] -> OR Output: -1.000\n",
      "Input: [0, 1] -> OR Output: 1.000\n",
      "Input: [1, 0] -> OR Output: 1.000\n",
      "Input: [1, 1] -> OR Output: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Para los items de entrada my_x_collection la salida debería ser \n",
    "# -1, -1, -1, 1\n",
    "print('Testando el output de la neurona OR')\n",
    "#bucle para ir obteniendo el output de la neurona AND para cada item del input\n",
    "for my_x in my_x_collection:\n",
    "    print(f'Input: {my_x} -> OR Output: {or_neuron(my_x):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X-OR\n",
    "\n",
    "![X-OR](xorToLearnWeights.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando una neurona XOR hasta convergencia\n",
      "Vuelta 1: Pesos actualizados XOR: [-0.3656357558875988, 1.8474337369372327, -0.23622538102338586]\n",
      "Vuelta 2: Pesos actualizados XOR: [-0.8656357558875988, 0.8474337369372327, -1.2362253810233859]\n",
      "Vuelta 3: Pesos actualizados XOR: [-0.8656357558875988, 0.8474337369372327, -1.2362253810233859]\n"
     ]
    }
   ],
   "source": [
    "# Combinando una puerta OR y una AND, y aprendiendo el peso que hay que darle a cada una para obtener un XOR \n",
    "from random import seed, random\n",
    "\n",
    "# Inicializaciones\n",
    "print('Entrenando una neurona XOR hasta convergencia')\n",
    "xorConverge=True\n",
    "seed(1)\n",
    "\n",
    "xorWeights= [random() for i in range(3)]\n",
    "xorBias   = -0.5\n",
    "xorGoldOutputs=[1,-1,-1,1]\n",
    "\n",
    "# Entrenando\n",
    "numeroVuelta = 0\n",
    "while xorConverge:\n",
    "    xorConverge = False\n",
    "    for i, my_x in enumerate(my_x_collection):\n",
    "        # Usar las salidas de las puertas AND y OR como entradas para la XOR\n",
    "        and_output = and_neuron(my_x)\n",
    "        or_output = or_neuron(my_x)\n",
    "        \n",
    "        # Crear el nuevo vector de entrada con los resultados de AND y OR\n",
    "        new_x = [xorBias, and_output, or_output]\n",
    "        \n",
    "        # Verificar si la predicción coincide con el valor esperado\n",
    "        if neuron([and_output, or_output], xorWeights, xorBias) != xorGoldOutputs[i]:\n",
    "            # Ajuste de pesos\n",
    "            adjustment = 1 if xorGoldOutputs[i] == 1 else -1\n",
    "            xorWeights = [xorWeights[j] + adjustment * new_x[j] for j in range(len(xorWeights))]\n",
    "            xorConverge = True  # Continuar iterando hasta convergencia\n",
    "    numeroVuelta += 1\n",
    "    print(f\"Vuelta {numeroVuelta}: Pesos actualizados XOR:\", xorWeights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor_neuron(x):\n",
    "    \"\"\"\n",
    "    Return x1_ * x2 + x1 * x2_\n",
    "    \"\"\"\n",
    "    xor_w    = [-1.115635755887599, 0.3474337369372327, -0.7362253810233859]\n",
    "    xor_bias = -0.5\n",
    "    new_x=list()\n",
    "    new_x.append(and_neuron(x))\n",
    "    new_x.append(or_neuron(x))\n",
    "    return neuron(new_x, xor_w, xor_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking XOR neuron output\n",
      "[0, 0] 1.000\n",
      "[0, 1] -1.000\n",
      "[1, 0] -1.000\n",
      "[1, 1] 1.000\n"
     ]
    }
   ],
   "source": [
    "print('Checking XOR neuron output')\n",
    "for my_x in my_x_collection:\n",
    "    print(my_x, f'{xor_neuron(my_x):.3f}')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "tia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
